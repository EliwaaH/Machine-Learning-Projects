# -*- coding: utf-8 -*-
"""ML-ZoomCamp-Car-Price-Predicition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10ruxLgcQjVXNf-PVWPnUk16iXhX2Bz7h
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

data = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv'
!wget $data

df = pd.read_csv(data)

df.head()

df.columns = df.columns.str.lower().str.replace(' ', '_')
df.head()

strings_list = list(df.columns[df.dtypes == 'object'])

strings_list

for col in strings_list:
  df[col] = df[col].str.lower().str.replace(' ', '_')

df.head()

df['msrp'] = np.log1p(df['msrp'])
sns.histplot(df.msrp, bins=50)

df.isnull().sum()

n = len(df)
n_val = int(n * 0.2)
n_test = int(n * 0.2)
n_train = n - (n_test + n_val)
n, n_train, n_val, n_test

idx = np.arange(n)
np.random.seed(2)
np.random.shuffle(idx)

df_train = df.iloc[idx[:n_train]]
df_val = df.iloc[idx[n_train:n_train+n_val]]
df_test = df.iloc[idx[n_train + n_val:]]

len(df_train), len(df_val), len(df_test)

df_train.head()

df_train = df_train.reset_index(drop = True)
df_test = df_test.reset_index(drop = True)
df_val = df_val.reset_index(drop = True)

y_train = df_train['msrp']
y_val = df_val['msrp']
y_test = df_test['msrp']

y_train

del df_train['msrp']
del df_val['msrp']
del df_test['msrp']

df_train.columns

"""***These Features will be the training features***"""

base = ['engine_hp', 'engine_cylinders', 'highway_mpg',
        'city_mpg', 'popularity']

"""**Here I am making a function that will prepare every x either train or valid or test**"""

def Prepare_X(df):
  df_pre = df[base]
  df_pre = df_pre.fillna(0)
  X = df_pre.values
  return X

"""***Now, Train our linear regression model***"""

def train_linear_regerssion_model(X, y):
  X = np.column_stack([np.ones(X.shape[0]), X])
  XTX = X.T.dot(X)
  XTX_inv = np.linalg.inv(XTX)
  w_full = XTX_inv.dot(X.T).dot(y)
  return w_full[0], w_full[1:]

X_train = Prepare_X(df_train)
w0, w = train_linear_regerssion_model(X_train, y_train)
y_pred = w0 + X_train.dot(w)

sns.histplot(y_pred, color= 'red', alpha=0.5, bins=50)
sns.histplot(y_train, color='blue', alpha=0.5, bins=50)

"""***Now we will check the model performance usinf RMSE***"""

def RMSE(y, y_prediction):
  diff = (y_prediction - y)**2
  mean_diff = np.mean(diff)
  rmse = np.sqrt(mean_diff)
  return rmse

RMSE(y_train, y_pred)

"""***Now we will validate our model using validation data***"""

X_val = Prepare_X(df_val)
y_pred = w0 + X_val.dot(w)

RMSE(y_val, y_pred)

"""***In the Next Steps we will using more features and using catgorical features in our training process***"""

df_train.dtypes

df.head()

df['year'].max()

Categorical_columns = ['make', 'model', 'engine_fuel_type', 'driven_wheels', 'market_category',
    'vehicle_size', 'vehicle_style']

Categorical = {}

for t in Categorical_columns:
  Categorical[t] = list(df_train[t].value_counts().head().index)

Categorical

def Prepare_X(df):
  df = df.copy()
  df['age'] = 2017 - df['year']
  features = base + ['age']

  ##Number of doors
  for c in range(2, 5):
    df['num_doors_%d' %c] = (df['number_of_doors'] == c).astype(int)
    features.append('num_doors_%d' %c)
  
  for i, k in Categorical.items():
    for value in k:
      df['%s %s' % (i, value)] = (df[i] == value).astype(int)
      features.append('%s %s' % (i, value))
  df_num = df[features]
  df_num = df_num.fillna(0)
  X = df_num.values

  return X

x_train = Prepare_X(df_train)
x_val = Prepare_X(df_val)
w0, w = train_linear_regerssion_model(x_train, y_train)
y_pred = w0 + x_train.dot(w)
y_predd = w0 + x_val.dot(w)


print(RMSE(y_train, y_pred))
print(RMSE(y_val, y_predd))

"""***As we can see RMSE is too large so we have to make it better and to do thsi we have to use regilarization***"""

def train_linear_regerssion_model_regilrization(x, y, r = 0.0001):
  x = np.column_stack([np.ones(x.shape[0]), x])
  XTX = x.T.dot(x)
  XTX = XTX + r * np.eye(XTX.shape[0])
  XTX_inv = np.linalg.inv(XTX)
  w_full = XTX_inv.dot(x.T).dot(y)

  return w_full[0], w_full[1:]

x_train = Prepare_X(df_train)
x_val = Prepare_X(df_val)

w0, w = train_linear_regerssion_model_regilrization(x_train, y_train, r = 0.01)
y_predit  = w0 + x_train.dot(w)
y_preditt = w0 + x_val.dot(w)

print(RMSE(y_train, y_predit))
print(RMSE(y_val, y_preditt))

"""***As we can see the result is different from the above one after doing regilarization, Now we will Tune our model by chooisng the best value for r that get the best results***"""

for r in [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 10]:
  x_train = Prepare_X(df_train)
  x_val = Prepare_X(df_val)

  w0, w = train_linear_regerssion_model_regilrization(x_train, y_train, r = r)
  y_predit = w0 + x_val.dot(w)
  score = RMSE(y_val, y_predit)
  print(r, w0, score)

"""***Now after getting the best value for r we are in the final step which we will use our model on test data***"""

df_full_train = pd.concat([df_train, df_val])
df_full_train = df_full_train.reset_index(drop = True)

X_full_train = Prepare_X(df_full_train)

y_full_train = np.concatenate([y_train, y_val])

w0, w = train_linear_regerssion_model_regilrization(X_full_train, y_full_train, r=0.0001)

x_test = Prepare_X(df_test)

y_predict = w0 + x_test.dot(w)
RMSE(y_test, y_predict)

"""***Now let's test the model on a real car to get it's price***"""

test_car = df_test.iloc[40].to_dict()
df_car_test = pd.DataFrame([test_car])

X_car_test = Prepare_X(df_car_test)

y_pred = w0 + X_car_test.dot(w)

car_price = y_pred[0]

car_price

car_price = np.expm1(car_price)
car_price

real_price = np.expm1(y_test[40])
real_price